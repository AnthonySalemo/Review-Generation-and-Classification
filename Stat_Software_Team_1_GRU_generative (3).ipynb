{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Generative Model"
      ],
      "metadata": {
        "id": "tDgpU1ilIZ30"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNwdemXLiCG9",
        "outputId": "d10a2694-9d9c-479e-90bd-eaac7e9f5844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Colab Notebooks/Project\n"
          ]
        }
      ],
      "source": [
        "#Opening csv files location\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #, force_remount=True\n",
        "%cd drive/My Drive/Colab Notebooks/Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RfIbU3wWujly"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "from nltk.util import ngrams\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import random\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WBwAzCRLOB6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9baa0cef-d2c8-480e-ccbf-aee094ba3d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e48d7b8ee2cc>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  Complete_Reviews['Review']=Complete_Reviews['Review'].str.replace('<[^>]+>', '')\n",
            "<ipython-input-3-e48d7b8ee2cc>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  Complete_Reviews['Review']=Complete_Reviews['Review'].str.replace('[^A-Za-z0-9 ]+', '')\n"
          ]
        }
      ],
      "source": [
        "AllReviews = pd.read_csv('Data/AllReviews.csv')\n",
        "AllReviews = AllReviews.loc[(AllReviews[\"titleType\"] == \"tvMovie\")|(AllReviews[\"titleType\"] == \"movie\")]\n",
        "\n",
        "Reviews_Genres_Title = AllReviews[[\"Review\", \"genres\"]]\n",
        "Reviews_Genres_Title = Reviews_Genres_Title.drop_duplicates()\n",
        "Reviews_Genres_Title = Reviews_Genres_Title.loc[Reviews_Genres_Title[\"Review\"].isna() == False]\n",
        "Reviews_Genres_Title = Reviews_Genres_Title.drop(Reviews_Genres_Title.loc[(Reviews_Genres_Title[\"genres\"] =='\\\\N')==True].index)\n",
        "\n",
        "Complete_Reviews = Reviews_Genres_Title.copy()\n",
        "Complete_Reviews['Review']=Complete_Reviews['Review'].str.lower()\n",
        "Complete_Reviews['Review']=Complete_Reviews['Review'].str.replace('<[^>]+>', '')\n",
        "Complete_Reviews['Review']=Complete_Reviews['Review'].str.replace('[^A-Za-z0-9 ]+', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hxGWXJtAOB6u"
      },
      "outputs": [],
      "source": [
        "#Every unique character left in the movie reviews\n",
        "vocab = sorted(set(' '.join(Complete_Reviews['Review'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5447k65DOB6u"
      },
      "outputs": [],
      "source": [
        "#Every review saved in one string\n",
        "text = ' '.join(Complete_Reviews['Review'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KiKsFXjiOB6u",
        "outputId": "6c72032d-960b-4d22-f972-05a8566a1010"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'  0 1 2 3 4 5 6 7 8 9 a b c d e f g h i j k l m n o p q r s t u v w x y z'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Every character in vocab\n",
        "' '.join(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aguafLWbOB6v"
      },
      "outputs": [],
      "source": [
        "#Break data into arrays of single characters\n",
        "chars = tf.strings.unicode_split(Complete_Reviews['Review'], input_encoding='UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o0mGlg9IOB6w"
      },
      "outputs": [],
      "source": [
        "#Encoder ids\n",
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mABDMCKcOB6w"
      },
      "outputs": [],
      "source": [
        "ids = ids_from_chars(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "znWWthLDOB61"
      },
      "outputs": [],
      "source": [
        "#Decoder ids\n",
        "chars_from_ids = tf.keras.layers.StringLookup(vocabulary = ids_from_chars.get_vocabulary(), invert = True, mask_token = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Yzm96bXwOB62"
      },
      "outputs": [],
      "source": [
        "#Function to get text back from the ids\n",
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Kn1EtZrWOB62"
      },
      "outputs": [],
      "source": [
        "#All mapped ids from the reviews text\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TFoSUAjAOB63"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8Sd4aqvuOB63"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "JICn9DGdOB63"
      },
      "outputs": [],
      "source": [
        "sequences= ids_dataset.batch(seq_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "A7AmICyBOB64"
      },
      "outputs": [],
      "source": [
        "#Take a sequence and break it into two texts. One excludes the last element, one excludes the first.\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yt3swL2OB64",
        "outputId": "8f03dcdc-612e-4eeb-db11-7f611ef1cf5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['M', 'o', 'v', 'i', 'e', 'R', 'e', 'v', 'i', 'e'],\n",
              " ['o', 'v', 'i', 'e', 'R', 'e', 'v', 'i', 'e', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "#Visual of split input function\n",
        "split_input_target(list(\"MovieReview\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mLG5edkBOB64"
      },
      "outputs": [],
      "source": [
        "#Map the split_input_target function into the sequences\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "YVGLP8tkIeCc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vogY8Bt7OB65",
        "outputId": "8a39c53c-d334-401b-ef1c-61ac7e3b592a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KB8UsGY6fyE"
      },
      "source": [
        "Setting up GRU architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xPcjNL1VOB67"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AoJIxyXbOB67"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    #Embedding layer where each character in vocab is dimensionally increased from 1 to 256\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    #GRU layer with 1024\n",
        "    self.gru= tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    #layer to truncate back down to 38\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    #Pass the inputs into the embedding layer\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    #Pass inputs into gru layer\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    #Pass inputs into dense layer\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    #If return state from GRU set to true, return state and output character\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    #Otherwise return just output character\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5DvHMqTfOB68"
      },
      "outputs": [],
      "source": [
        "#Set up the model with specified parameters\n",
        "gru_model = MyModel(vocab_size=vocab_size, embedding_dim=embedding_dim, rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiVem0aQOB68",
        "outputId": "3ed6e098-7d84-4f96-8982-ceba41e71733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 38) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "#Initialize the model with a single example\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = gru_model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Lmzn8mnjOB69"
      },
      "outputs": [],
      "source": [
        "#Use sparse categorical cross entropy loss\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2n9uaGAOB69",
        "outputId": "7e65f047-7e9d-4821-fe2c-9be7bf5dd979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 38)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(3.6383917, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqNmEnPGOB6-",
        "outputId": "73063139-f6dd-4f6f-f0e1-2d1dbfd187e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38.026863"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#Perplexity of untrained model\n",
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wUhiqRCOB68",
        "outputId": "2165ef4d-4fb6-451e-ec46-73423f2fd993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  9728      \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  38950     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3986982 (15.21 MB)\n",
            "Trainable params: 3986982 (15.21 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "gru_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "eCjNVuULOB6-"
      },
      "outputs": [],
      "source": [
        "gru_model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "SbGT5fCjOB6-"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = 'Data/training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7tU1pAY2qcq"
      },
      "outputs": [],
      "source": [
        "#Use this line to reload previously saved models\n",
        "gru_model.load_weights(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Aj0W-ezOB6-",
        "outputId": "4a8f3277-6d0a-4c9c-91c5-f6d5d6eb562f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "15589/15589 [==============================] - 938s 60ms/step - loss: 1.2358\n",
            "Epoch 2/2\n",
            "15589/15589 [==============================] - 936s 60ms/step - loss: 1.1641\n"
          ]
        }
      ],
      "source": [
        "history = gru_model.fit(dataset, epochs=2, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation"
      ],
      "metadata": {
        "id": "E5kQ-4XPIoiw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "JJFtO4L_OB6_"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    #Temperature not significant for this project\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    #Temperature is set to 1 so prediction does not change\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xPcvgykjOB6_"
      },
      "outputs": [],
      "source": [
        "#Set up model class by saving model, characters, and ids\n",
        "one_step_model = OneStep(gru_model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xUm-04_eOB7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f39095-1152-40bb-fccf-631dcb7a6ba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "and this a second of time to see how good then anyway an oscar manorpex of women somewhere to prove this movieif your dramatic red husses and getting just decided if one of their easily shows you from it its that because they think so obviously its like that it has potential to rule these kinds of louds of murderer the fbi the beginning creepinchitorious yet good deben and that excel it looks for its simple filmmakings i want to give i and your money a go to me expecting progress in their blue convincing or the planet of canned identity and wasted appearance during pail shop your guerlor conceit it to be believable and stepinestrai a rush teenagend soul of the main character disheartens or lame but i sticked this movie at baltmas i can yep i confirm the ex endered footbest credit of the lives go and gave this movie a 210t option our outcuffin real and emotional performances as a house of rands in the hotel for him to proving the son columbus let just hehemovie easily confronts drinki nervous r \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.383988618850708\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['and this'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n')\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['and this'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n')\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6K_o64EE_5_",
        "outputId": "1a0c12fd-088f-498b-e0c3-dfd709849813"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "and this is not at the end i think the scene was mesisting not convincing photographer that is also supposed to be conflicts noncluding vehicle for a koreadam they dont watch the trelow slums make no euroverneh and has it really because a documentary youve got last noticed especially jennas broadcast for being in most state this movie akmelp especially his girlfriend associated me im sorry to put only one of the bow by laughing in mime face and then film a lot before comes so off great animation of the usa which gives you great methods cartoon having this attackal rouge mesimatious string of almost never even safefear why is it a bit better than the usual story which people would pows up to say away all the fears foremes admirtedly house to be confusing for your colleagurous minded attack signators when youre opinionalthiny a few things that the worst internological letters the directorcoming down to an interrogate parallel relationship to work up you viewer get real never shows that he motel  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.537088632583618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model/chars/and ids\n",
        "tf.saved_model.save(one_step_model, 'two_epoch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlDVlYGuFGsF",
        "outputId": "110d8bbf-e05d-4513-a981-c086b8e274f9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7cf5ed40a9b0>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load previously saved models\n",
        "one_step_model = tf.saved_model.load('two_epoch')"
      ],
      "metadata": {
        "id": "QKLg44V1KMRd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['and then'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1RsnE76fIkw",
        "outputId": "3748cfa1-93ae-4d90-d7c3-ed11cf25d627"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "and then there is a total remairs performance and man while therative and consumers i loved himat very very strong perpetrated shelter and policy here and irritate to truck to just a story of art calls out and was moving this movie tracles whyand reevel their stories  the second polarthrough lives excellent experience were trying rather than bammildgreen and thriller there is also so i missed the summer than theyre believable in the end of the film i also thought that that marco bollytey do where the game one rats is treated by two bratawams pain marculatelli who enjoy broadcast with her talent there wasnt anything happens to see what it didnt buy major it goes up it there is pleghm oh dreadful engaging ending dont waste your time someweeks why i mean stephen douglas srommen henry bradfor vin syba binoche was eradicated by a revelation of the original story not a totello with the environment for the film which is completely awful the film cant have happened when you get to steal the pure half  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.278277635574341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zg51zsd8Ie6",
        "outputId": "0fd20e66-fa36-4df9-ddd7-11656d683757"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
              "array([b'and then goverments through streets from other films in spiteafor is planned to bg that someone wit a palpable and so eating i love the pile of screen time this really makes this movie a 2 unless youve seen this movie and i like the film or better i am a fan of a swing people and collectival part of acting by slightly mental action but aproophobly pauls shakespeared stuntman in queentity theyre all too hard for che is to go about exhibs not to actually be remember the alien photography with amciting young cold get hey home natural the director reveal the true review that moves well as i had one night with the specific looks of the first baskern french couple with completely predictable metal industry but there is nothing going on because thi wasnt an awesome copy of it just because that is the end of a real story and since pound with their traple pinewiper who actually die for this film consequences anylooking good economic kne dont poss music red as come on this glass her bit the ending was s'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "#Generate a dictionary of reviews\n",
        "reviews = {}\n",
        "for i in range(1000):\n",
        "  states = None\n",
        "  next_char = tf.constant(['and then'])\n",
        "  result = [next_char]\n",
        "  #Generate a review of character length from 500 to 1000\n",
        "  for n in range(random.randint(500,1000)):\n",
        "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "    result.append(next_char)\n",
        "\n",
        "  reviews[i] = tf.strings.join(result)\n",
        "  if i%100 ==0:\n",
        "    iter = time.time()\n",
        "    print(\"Review:\", i, \"    Run time:\", iter-start)\n",
        "end = time.time()\n",
        "print('Total Reviews:', len(reviews))\n",
        "print('\\n Total Run time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHJeCs9J8BpD",
        "outputId": "1c51577b-5b79-4664-a445-98679eac18a7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: 0     Run time: 2.9246339797973633\n",
            "Review: 100     Run time: 235.5458586215973\n",
            "Review: 200     Run time: 491.53173661231995\n",
            "Review: 300     Run time: 713.2154879570007\n",
            "Review: 400     Run time: 942.9624216556549\n",
            "Review: 500     Run time: 1164.3898103237152\n",
            "Review: 600     Run time: 1409.6759459972382\n",
            "Review: 700     Run time: 1645.5105111598969\n",
            "Review: 800     Run time: 1877.3839061260223\n",
            "Review: 900     Run time: 2135.1558017730713\n",
            "Total Reviews: 1000\n",
            "\n",
            " Total Run time: 2356.717267036438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_tocsv = []\n",
        "for i in range(len(reviews)):\n",
        "  #Remove the prompt 'and then' after decoding reviews\n",
        "  rev = reviews[i].numpy()[0].decode(\"utf-8\")[9:]\n",
        "  review_tocsv.append([i+1, \"GRU\", \"and then\", rev])"
      ],
      "metadata": {
        "id": "xNeAnSJu2Q79"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write reviews to csv\n",
        "with open('gru_genReviews5.csv', 'w', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow([\"Review Number\",\"model\", \"prompt\", \"Review\"])\n",
        "  for i in range(len(review_tocsv)):\n",
        "    writer.writerow(review_tocsv[i])"
      ],
      "metadata": {
        "id": "4hr7UjIczh0b"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perplexity"
      ],
      "metadata": {
        "id": "8z_8x405LqC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "total_loss = []\n",
        "\n",
        "for batch, labels in dataset.take(100):\n",
        "\n",
        "    outputs = gru_model(batch)\n",
        "    losses = loss(labels, outputs).numpy()\n",
        "    total_loss.append(losses)\n",
        "\n",
        "perplexity = np.exp(np.mean(total_loss))\n",
        "perplexity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPzgD_nYtHqJ",
        "outputId": "a1cbfce5-eb95-4d08-a162-f797b74bfd3b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.4962916"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perplexity without training = 38.03.\n",
        "Perplexity training for 1 and 2 epochs = 3.5\n",
        "Perplexity training for 10 epochs = 8.1"
      ],
      "metadata": {
        "id": "-3wg7vVmfTKg"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}