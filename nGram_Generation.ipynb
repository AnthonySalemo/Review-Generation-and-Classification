{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzmQXNHP2bW8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "from nltk.util import ngrams\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiKACAcQ2iFw",
        "outputId": "9e607859-8aa7-4b19-9de9-fb5ff35ff478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhXjyGue2jTp",
        "outputId": "5434873d-3ed6-4d7b-b084-59ad3393f5e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Acquire the dataset from AllReviews csv file and clean it up to a usable form\n",
        "reviews_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AllReviews.csv')\n",
        "reviews_df = reviews_df.loc[(reviews_df[\"titleType\"] == \"tvMovie\")|(reviews_df[\"titleType\"] == \"movie\")]\n",
        "\n",
        "def simple_tokenizer(text): #\n",
        "    text = str(text)\n",
        "    if text == 'nan':\n",
        "        return []\n",
        "    text = re.sub(r'<[^>]+>', ' ', text)  # Remove HTML tags. Unlikely needed although a double check wouldn't hurt.\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)  # Filter to allow only alphabet letters\n",
        "    text = text.lower()  # Convert to lower case\n",
        "    # Tokenize by splitting the sentences into words\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Tokenize the reviews. Replace 'Review' column depending on.\n",
        "reviews_df['Review'] = reviews_df['Review'].astype(str)\n",
        "tokenized_reviews = reviews_df['Review'].apply(simple_tokenizer)\n",
        "flat_token_list = [token for sublist in tokenized_reviews for token in sublist]\n",
        "\n",
        "unigrams = flat_token_list\n",
        "bigrams = list(ngrams(flat_token_list, 2))\n",
        "trigrams = list(ngrams(flat_token_list, 3))\n",
        "\n",
        "# Count the frequencies of each n-gram.\n",
        "unigram_counts = Counter(unigrams)\n",
        "bigram_counts = Counter(bigrams)\n",
        "trigram_counts = Counter(trigrams)\n",
        "\n",
        "# Display the most common n-grams. We expect words like \"the\" and \"a\" to be the most common.\n",
        "print('Most common unigrams:', unigram_counts.most_common(5))\n",
        "print('Most common bigrams:', bigram_counts.most_common(5))\n",
        "print('Most common trigrams:', trigram_counts.most_common(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiCY8gfM2joe",
        "outputId": "b79d9d11-926f-47fc-cdec-065a326b4e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common unigrams: [('the', 1072757), ('a', 526387), ('and', 519940), ('of', 469101), ('to', 431304)]\n",
            "Most common bigrams: [(('of', 'the'), 124622), (('in', 'the'), 81830), (('this', 'movie'), 53054), (('the', 'film'), 44411), (('is', 'a'), 43293)]\n",
            "Most common trigrams: [(('one', 'of', 'the'), 15740), (('this', 'movie', 'is'), 8874), (('of', 'the', 'film'), 8617), (('this', 'is', 'a'), 7884), (('a', 'lot', 'of'), 7409)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_counts = defaultdict(Counter)\n",
        "\n",
        "for w1, w2 in bigrams:\n",
        "    bigram_counts[w1][w2] += 1\n",
        "\n",
        "# Convert the counts to probabilities for the bigram model\n",
        "for w1 in bigram_counts:\n",
        "    total_count = float(sum(bigram_counts[w1].values()))\n",
        "    for w2 in bigram_counts[w1]:\n",
        "        bigram_counts[w1][w2] /= total_count"
      ],
      "metadata": {
        "id": "b7PQUiSD4ElH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_counts = defaultdict(Counter)\n",
        "\n",
        "for w1, w2, w3 in trigrams:\n",
        "    trigram_counts[(w1, w2)][w3] += 1\n",
        "\n",
        "for w1_w2 in trigram_counts:\n",
        "    total_count = sum(trigram_counts[w1_w2].values())\n",
        "    for w3 in trigram_counts[w1_w2]:\n",
        "        trigram_counts[w1_w2][w3] /= total_count\n"
      ],
      "metadata": {
        "id": "Zqs0BG-b28xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_synthetic_reviews = 5000  # adjust as needed"
      ],
      "metadata": {
        "id": "pncjVFCq5WMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_review_unigram(unigram_counts, num_words=50):\n",
        "    words = list(unigram_counts.keys())\n",
        "    word_probabilities = [unigram_counts[word] for word in words]\n",
        "    review = [random.choices(words, weights=word_probabilities)[0] for _ in range(num_words)]\n",
        "    return ' '.join(review)\n",
        "\n",
        "synthetic_reviews = [generate_synthetic_review_unigram(unigram_counts) for _ in range(num_synthetic_reviews)]\n",
        "\n",
        "unigram_reviews = pd.DataFrame({'review': synthetic_reviews, 'model': 'unigram'})\n",
        "unigram_reviews.to_csv('/content/drive/MyDrive/results/unigram_reviews.csv', index=False)"
      ],
      "metadata": {
        "id": "Hsz9tHY74rab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_review_bigram(bigram_counts, num_words=50):\n",
        "    if not bigram_counts:\n",
        "        return \"\"\n",
        "\n",
        "    # Start with a random word\n",
        "    current_word = random.choice(list(bigram_counts.keys()))\n",
        "    review = [current_word]\n",
        "\n",
        "    for _ in range(num_words - 1):\n",
        "        next_words = list(bigram_counts[current_word].keys())\n",
        "        next_word_weights = list(bigram_counts[current_word].values())\n",
        "        next_word = random.choices(next_words, weights=next_word_weights)[0]\n",
        "        review.append(next_word)\n",
        "        current_word = next_word\n",
        "\n",
        "    return ' '.join(review)\n",
        "\n",
        "# Generate synthetic reviews using bigram model\n",
        "synthetic_reviews_bigram = [generate_synthetic_review_bigram(bigram_counts) for _ in range(num_synthetic_reviews)]\n",
        "\n",
        "bigram_reviews = pd.DataFrame({'review': synthetic_reviews_bigram, 'model': 'bigram'})\n",
        "bigram_reviews.to_csv('/content/drive/MyDrive/results/bigram_reviews.csv', index=False)"
      ],
      "metadata": {
        "id": "6nMjq7285OvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_review_trigram(trigram_counts, num_words=50):\n",
        "    if not trigram_counts:\n",
        "        return \"\"\n",
        "\n",
        "    # Start with a random bigram\n",
        "    start_bigram = random.choice(list(trigram_counts.keys()))\n",
        "    review = list(start_bigram)\n",
        "\n",
        "    for _ in range(num_words - 2):\n",
        "        next_words = list(trigram_counts[start_bigram].keys())\n",
        "        if not next_words:\n",
        "            break\n",
        "        next_word_weights = list(trigram_counts[start_bigram].values())\n",
        "        next_word = random.choices(next_words, weights=next_word_weights)[0]\n",
        "        review.append(next_word)\n",
        "        start_bigram = (start_bigram[1], next_word)\n",
        "\n",
        "    return ' '.join(review)\n",
        "\n",
        "# Generate synthetic reviews using trigram model\n",
        "synthetic_reviews_trigram = [generate_synthetic_review_trigram(trigram_counts) for _ in range(num_synthetic_reviews)]\n",
        "\n",
        "trigram_reviews = pd.DataFrame({'review': synthetic_reviews_trigram, 'model': 'trigram'})\n",
        "trigram_reviews.to_csv('/content/drive/MyDrive/results/trigram_reviews.csv', index=False)"
      ],
      "metadata": {
        "id": "hAFgEX605cgS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}